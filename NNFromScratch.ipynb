{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9128f2",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cf990",
   "metadata": {},
   "source": [
    "The goal of this notebook is to build from scratch a neural network for an image classficiation task.\n",
    "\n",
    "This is to have a good grasp of deep learning concepts .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44e778",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccca0e2",
   "metadata": {},
   "source": [
    "**1-** Prepare the dataset\n",
    "\n",
    "**2-** Implementing the forward pass\n",
    "\n",
    "**3-** Implementing the backwad pass\n",
    "\n",
    "**4-** Evaluating the performance of the nn\n",
    "\n",
    "**5-** Experiments with the nn parametres and how they affect the performances \n",
    "\n",
    "Some questions that we want to answer are : \n",
    "\n",
    "* Can we find some correlation between the variance in the dataset and the size of the neural network? \n",
    "* Is the bias part of the neurons important in the task?\n",
    "* Does the activation function affects the value to be choosen for the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8dec1",
   "metadata": {},
   "source": [
    "### 1-  Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe544e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test data shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Display the shape of the loaded data\n",
    "print(\"Training data shape:\", x_train.shape)  # (60000, 28, 28)\n",
    "print(\"Training labels shape:\", y_train.shape)  # (60000,)\n",
    "print(\"Test data shape:\", x_test.shape)  # (10000, 28, 28)\n",
    "print(\"Test labels shape:\", y_test.shape)  # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41459d3c",
   "metadata": {},
   "source": [
    "###  2-  Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9642a8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "random_idx = np.random.randint(1000)\n",
    "\n",
    "image = x_train[random_idx]\n",
    "label = y_train[random_idx]\n",
    "def visualizeImage(image,label):\n",
    "    plt.imshow(image, cmap='gray')  # Display the image\n",
    "    plt.axis('off')  # Turn off the axes\n",
    "    plt.title(label)\n",
    "    plt.show()  # Show the image\n",
    "visualizeImage(image,label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026407de",
   "metadata": {},
   "source": [
    "==> Each image is a **28*28** pixels, which gives a list of **784** elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adace72",
   "metadata": {},
   "source": [
    "### 3- Implementing the forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c35",
   "metadata": {},
   "source": [
    "Our neural network, would be such that there is only one hidden layer with **300** neurons, and the output layer with **10**neurons\n",
    "\n",
    "For now, the activations functions would be all linear, and in to generate the output we take the argmax.\n",
    "\n",
    "Our loss function will be the Mean Squared Error, aka **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27c41a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2a15531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "## Initializing the weights linking the input layer with the hidden layer\n",
    "\n",
    "size_input_layer = len(input_layer) #784\n",
    "size_hidden_layer = 300\n",
    "size_output_layer = 10\n",
    "print(len(input_layer))\n",
    "\n",
    "weight_input_hidden = np.random.random((size_hidden_layer, size_input_layer))\n",
    "weight_input_hidden = np.random.random((size_input_layer, size_hidden_layer))\n",
    "weight_hidden_output = np.random.random((size_hidden_layer, size_output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f6d65eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96a69d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (784,300) and (784,) not aligned: 300 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Hidden layer result\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hidden_representation \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_input_hidden\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m hidden_representation\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (784,300) and (784,) not aligned: 300 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Hidden layer result\n",
    "hidden_representation = np.dot(input_layer, weight_input_hidden)\n",
    "hidden_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e7548a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = hidden_representation.min()\n",
    "ma = hidden_representation.max()\n",
    "\n",
    "# min max normalization\n",
    "norm_hidden_representation = (hidden_representation - mi)/(ma-mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b7c3057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x225433d3850>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(norm_hidden_representation.reshape(15,20), cmap='gray')  # Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c98c86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hidden output result \n",
    "\n",
    "ouput_result = np.dot(norm_hidden_representation, weight_hidden_output)\n",
    "ouput_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f29aa6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result of the forward pass\n",
    "ouput_result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16af9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that takes as an input the input layer(vector) and parameters and returns the predicted written number\n",
    "def predictNumber(input_layer, weight_input_hidden, weight_hidden_output):\n",
    "    size_input_layer = len(input_layer) #784\n",
    "    size_hidden_layer = 300\n",
    "    size_output_layer = 10\n",
    "\n",
    "    hidden_representation = np.dot(weight_input_hidden , input_layer)\n",
    "    mi = hidden_representation.min()\n",
    "    ma = hidden_representation.max()\n",
    "\n",
    "    # min max normalization\n",
    "    norm_hidden_representation = (hidden_representation - mi)/(ma-mi)\n",
    "\n",
    "    ouput_result = np.dot(norm_hidden_representation, weight_hidden_output)\n",
    "    # Result of the forward pass\n",
    "    result = ouput_result.argmax()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38dc3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that takes as an input the input layer(vector) and parameters and returns the hidden representation and the output result\n",
    "def forward_pass(input_layer, weight_input_hidden, weight_hidden_output):\n",
    "    size_input_layer = len(input_layer) #784\n",
    "    size_hidden_layer = 300\n",
    "    size_output_layer = 10\n",
    "\n",
    "    hidden_representation = np.dot(weight_input_hidden , input_layer)\n",
    "    mi = hidden_representation.min()\n",
    "    ma = hidden_representation.max()\n",
    "\n",
    "    # min max normalization\n",
    "    norm_hidden_representation = (hidden_representation - mi)/(ma-mi)\n",
    "\n",
    "    output_result = np.dot(norm_hidden_representation, weight_hidden_output)\n",
    "    \n",
    "    return hidden_representation, output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e342005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "visualizeImage(image, label)\n",
    "predictNumber(input_layer, weight_input_hidden, weight_hidden_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65cdad",
   "metadata": {},
   "source": [
    "### 4- Implementing the backward pass:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b62f0",
   "metadata": {},
   "source": [
    "This section would modify the *input_hidden_weights* and *hidden_output_weights* in order to make better predictions.\n",
    "\n",
    "The weights modifications would be based on the backpropagation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78149688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predicted, desired):\n",
    "    # This function takes as input numpy arrays and not lists\n",
    "    diff = 1/2 * ((predicted - desired)**2).sum()\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38bf9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(weights, image, label, lr = 0.01):\n",
    "    # We only modify the weights between the last and the penultimate layer\n",
    "    # weights is a tuple of matrices : weight_input_hidden & weight_hidden_output\n",
    "    \n",
    "    size_hidden_layer = 300\n",
    "    size_output_layer = 10\n",
    "    \n",
    "    # one hot encoding the label\n",
    "    desired = np.zeros(size_output_layer)\n",
    "    desired[int(label)] = 1\n",
    "    \n",
    "    weight_input_hidden, weight_hidden_output = weights\n",
    "    new_weight_input_hidden, new_weight_hidden_output = weight_input_hidden.copy(), weight_hidden_output.copy()\n",
    "    \n",
    "    input_layer = image.flatten() # flattening the image\n",
    "    \n",
    "    hidden_representation, output_result = forward_pass(input_layer, weight_input_hidden, weight_hidden_output) # forward pass\n",
    "    \n",
    "    output_result =  tf.nn.softmax(output_result) # softmax operation\n",
    "    \n",
    "    # gradient descent iteration # backward pass for the second layer\n",
    "    for j in range(size_output_layer):\n",
    "        for i in range(size_hidden_layer):\n",
    "            delta = (output_result[j] - desired[j]) * hidden_representation[i] * (1 - output_result[j]) * output_result[j]\n",
    "            new_weight_hidden_output[i][j] = new_weight_hidden_output[i][j] - lr*delta \n",
    "      \n",
    "    return new_weight_input_hidden, new_weight_hidden_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e7365aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_pass(weights, image, label, lr = 0.01):\n",
    "    # We only modify the weights between the last and the penultimate layer\n",
    "    # weights is a tuple of matrices : weight_input_hidden & weight_hidden_output\n",
    "    \n",
    "    size_hidden_layer = 300\n",
    "    size_output_layer = 10\n",
    "    \n",
    "    # one hot encoding the label\n",
    "    desired = np.zeros(size_output_layer)\n",
    "    desired[int(label)] = 1\n",
    "    \n",
    "    weight_input_hidden, weight_hidden_output = weights\n",
    "    new_weight_input_hidden, new_weight_hidden_output = weight_input_hidden.copy(), weight_hidden_output.copy()\n",
    "    \n",
    "    input_layer = image.flatten() # flattening the image\n",
    "    \n",
    "    hidden_representation, output_result = forward_pass(input_layer, weight_input_hidden, weight_hidden_output) # forward pass\n",
    "    \n",
    "    output_result =  tf.nn.softmax(output_result) # softmax operation\n",
    "    \n",
    "    delta_matrix = np.zeros((size_hidden_layer, size_output_layer))\n",
    "\n",
    "    # gradient descent iteration # backward pass for the second layer\n",
    "    for k in range(size_output_layer):\n",
    "        for j in range(size_hidden_layer):\n",
    "            delta = (output_result[k] - desired[k]) * hidden_representation[j] * (1 - output_result[k]) * output_result[k]\n",
    "            new_weight_hidden_output[j][k] = new_weight_hidden_output[j][k] - lr*delta \n",
    "\n",
    "            delta_matrix[j][k] = delta\n",
    "    \n",
    "    for j in range(size_hidden_layer):\n",
    "        for i in range(size_input_layer):\n",
    "            delta = np.sum(new_weight_hidden_output[j]* (delta_matrix[j]) * input_layer[i] / hidden_representation[j])\n",
    "            new_weight_input_hidden[j][i] = new_weight_input_hidden[j][i] - lr*delta \n",
    "\n",
    "\n",
    "    return new_weight_input_hidden, new_weight_hidden_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16af90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the backward pass \n",
    "\n",
    "# preparing the args\n",
    "\n",
    "weights = weight_input_hidden, weight_hidden_output\n",
    "image = x_train[random_idx]; input_layer = image.flatten()\n",
    "label = y_train[random_idx]\n",
    "# one hot encoding\n",
    "desired = np.zeros(size_output_layer)\n",
    "desired[int(label)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "136f29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip if you don't want to perform the backward pass\n",
    "new_weight_input_hidden, new_weight_hidden_output = full_backward_pass(weights, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0ab06bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, new_output = forward_pass(input_layer, weight_input_hidden, new_weight_hidden_output)\n",
    "norm_new_output = np.array(tf.nn.softmax(new_output)) # transforming the logits to probs\n",
    "MSE(norm_new_output, desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17557509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29795.922364317616"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, old_output = forward_pass(input_layer, weight_input_hidden, weight_hidden_output)\n",
    "norm_old_output = np.array(tf.nn.softmax(old_output))\n",
    "MSE(old_output, desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd8066d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   74.39696066,  -233.39786026,   -13.67398176,    52.38022133,\n",
       "          76.42062292,    73.89492291, -2329.48474152,  1595.44795131,\n",
       "          50.07764008,    76.12015836])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53bade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
